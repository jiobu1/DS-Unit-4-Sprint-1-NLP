{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.704918\n",
       "0    0.279178\n",
       "2    0.015904\n",
       "Name: ratingCategory, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of ratingCategory: 0 (Excellent), 1 (Good), 2 (Poor)\n",
    "train.ratingCategory.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nMagnificently powerful and intense. Caramels, dried peats, elegant cigar smoke, seeds scraped from vanilla beans, brand new pencils, peppercorn, coriander seeds, and star anise make for a deeply satisfying nosing experience. Silky caramels, bountiful fruits of ripe peach, stewed apple, orange pith, and pervasive smoke with elements of burnt tobacco. An abiding finish of smoke, dry spices, and banoffee pie sweetness. Close to perfection. Editor's Choice</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>4723</td>\n",
       "      <td>\\nPale, almost peach color. Light aromas of caramel, sweet citrus. Tastes of sweet caramel, faint bite of oak on the end. Simple, but clean and pleasant. You’d have to be careful mixing this — it would get lost easily — but it should be nice on the rocks or with seltzer.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>4393</td>\n",
       "      <td>\\nHighly anticipated, this release offers freshly-popped kettle corn, cinnamon, nutmeg, oak, hints of fruit and floral. Then it feels unbalanced, a bitter woodiness hiding hopeful flavors. Once the wood disappears there’s caramel, vanilla, and baking spice over heat. A drop of water corrects the dominant oak and gives this a sipper’s chance.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "1772  0      \n",
       "1578  4723   \n",
       "683   4393   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                     description  \\\n",
       "1772  \\nMagnificently powerful and intense. Caramels, dried peats, elegant cigar smoke, seeds scraped from vanilla beans, brand new pencils, peppercorn, coriander seeds, and star anise make for a deeply satisfying nosing experience. Silky caramels, bountiful fruits of ripe peach, stewed apple, orange pith, and pervasive smoke with elements of burnt tobacco. An abiding finish of smoke, dry spices, and banoffee pie sweetness. Close to perfection. Editor's Choice   \n",
       "1578  \\nPale, almost peach color. Light aromas of caramel, sweet citrus. Tastes of sweet caramel, faint bite of oak on the end. Simple, but clean and pleasant. You’d have to be careful mixing this — it would get lost easily — but it should be nice on the rocks or with seltzer.                                                                                                                                                                                              \n",
       "683   \\nHighly anticipated, this release offers freshly-popped kettle corn, cinnamon, nutmeg, oak, hints of fruit and floral. Then it feels unbalanced, a bitter woodiness hiding hopeful flavors. Once the wood disappears there’s caramel, vanilla, and baking spice over heat. A drop of water corrects the dominant oak and gives this a sipper’s chance.                                                                                                                      \n",
       "\n",
       "      ratingCategory  \n",
       "1772  0               \n",
       "1578  0               \n",
       "683   0               "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a few reviews from the \"Excellent\" category\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)\n",
    "train[train.ratingCategory == 0].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>5049</td>\n",
       "      <td>\\nIts age certainly shows, with a good dose of leather, tobacco, and barrel char. Sweet notes of caramel, toffee, and candied fruit try to rescue it, but ultimately fails toward the finish, leaving my mouth parched, leathery, and craving a glass of water (or a beer!). A bourbon with individuality, but it pains me to think what this could have been (or once was).</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>5071</td>\n",
       "      <td>\\nThe nose on this whiskey is like smelling a wet empty barrel; it's all oak, char, and cinnamon spice. The entry is thin, watery, and understated with light caramel and cinnamon. In the mid-palate, the oak tannins completely take over. It's not just oak spice, but the puckeringly dry, sour, and bitter tannins. This all leads to a bitter, bone dry finish. Good whiskey is a conversation between spirit and wood, but here the wood is doing all the talking.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>5046</td>\n",
       "      <td>\\nThis may be the best-known Belgian single grain whisky and it vies for attention with its perfumed nose of violet creams, acetone, and peach juice with ripe mango and papaya. Unfortunately, the body is lacking, yielding up a juicy collision of tropical fruits and icing sugar sweetness, but after that initial arrival, the torpid profile is rather unremarkable. The flavors die quickly, with some residual flavor trails persisting. All in all, a bit drab. €53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "303   5049   \n",
       "1525  5071   \n",
       "2161  5046   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                        description  \\\n",
       "303   \\nIts age certainly shows, with a good dose of leather, tobacco, and barrel char. Sweet notes of caramel, toffee, and candied fruit try to rescue it, but ultimately fails toward the finish, leaving my mouth parched, leathery, and craving a glass of water (or a beer!). A bourbon with individuality, but it pains me to think what this could have been (or once was).                                                                                                    \n",
       "1525  \\nThe nose on this whiskey is like smelling a wet empty barrel; it's all oak, char, and cinnamon spice. The entry is thin, watery, and understated with light caramel and cinnamon. In the mid-palate, the oak tannins completely take over. It's not just oak spice, but the puckeringly dry, sour, and bitter tannins. This all leads to a bitter, bone dry finish. Good whiskey is a conversation between spirit and wood, but here the wood is doing all the talking.       \n",
       "2161  \\nThis may be the best-known Belgian single grain whisky and it vies for attention with its perfumed nose of violet creams, acetone, and peach juice with ripe mango and papaya. Unfortunately, the body is lacking, yielding up a juicy collision of tropical fruits and icing sugar sweetness, but after that initial arrival, the torpid profile is rather unremarkable. The flavors die quickly, with some residual flavor trails persisting. All in all, a bit drab. €53   \n",
       "\n",
       "      ratingCategory  \n",
       "303   2               \n",
       "1525  2               \n",
       "2161  2               "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a few reviews from the \"Poor\" category\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)\n",
    "train[train.ratingCategory == 2].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Training Set into Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3269,) (818,) (3269,) (818,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[\"description\"],\n",
    "                                                   train[\"ratingCategory\"], \n",
    "                                                   test_size=0.2, \n",
    "                                                   stratify=train[\"ratingCategory\"], \n",
    "                                                   random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(stop_words = 'english', ngram_range = (1,2))\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), \n",
    "                 ('rfc', rfc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SUBMISSION 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=30, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('vect',\n",
       "                                              TfidfVectorizer(analyzer='word',\n",
       "                                                              binary=False,\n",
       "                                                              decode_error='strict',\n",
       "                                                              dtype=<class 'numpy.float64'>,\n",
       "                                                              encoding='utf-8',\n",
       "                                                              input='content',\n",
       "                                                              lowercase=True,\n",
       "                                                              max_df=1.0,\n",
       "                                                              max_features=None,\n",
       "                                                              min_df=1,\n",
       "                                                              ngram_range=(1,\n",
       "                                                                           2),\n",
       "                                                              norm='l2',\n",
       "                                                              preprocessor=None,\n",
       "                                                              smooth_idf=True,\n",
       "                                                              stop_words='english...\n",
       "                                        'rfc__min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc7f6db6c88>,\n",
       "                                        'rfc__n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc7f6db64e0>,\n",
       "                                        'vect__max_df': (0.75, 1.0),\n",
       "                                        'vect__max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc7f6db63c8>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__max_features': randint(5000, 10000),\n",
    "    'rfc__n_estimators': randint(100, 1000),\n",
    "    'rfc__max_depth':randint(1,20),\n",
    "    'rfc__max_leaf_nodes': randint(1, 10000),\n",
    "    'rfc__min_samples_split': randint(2, 40),\n",
    "    'rfc__min_samples_leaf': randint(1, 20),\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipe, parameters, cv=30, n_jobs=-1, verbose=1)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7102689486552567"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred = random_search.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.707557481028429"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__max_depth': 17,\n",
       " 'rfc__max_leaf_nodes': 8300,\n",
       " 'rfc__min_samples_leaf': 4,\n",
       " 'rfc__min_samples_split': 29,\n",
       " 'rfc__n_estimators': 762,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': 9397}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = random_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461  1             \n",
       "1  2604  1             \n",
       "2  3341  1             \n",
       "3  3764  1             \n",
       "4  2306  1             "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 70% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SUBMISSION 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('lsi',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('vect',\n",
       "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                                  decode_error='strict',\n",
       "                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                  encoding='utf-8',\n",
       "                                                  input='content',\n",
       "                                                  lowercase=True, max_df=1.0,\n",
       "                                                  max_features=None, min_df=1,\n",
       "                                                  ngram_range=(1, 2), norm='l2',\n",
       "                                                  preprocessor=None,\n",
       "                                                  smooth_idf=True,\n",
       "                                                  stop_words='english',\n",
       "                                                  strip_accents=...\n",
       "                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=None,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', sgdc)])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed: 17.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('lsi',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('vect',\n",
       "                                                         TfidfVectorizer(analyzer='word',\n",
       "                                                                         binary=False,\n",
       "                                                                         decode_error='strict',\n",
       "                                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                                         encoding='utf-8',\n",
       "                                                                         input='content',\n",
       "                                                                         lowercase=True,\n",
       "                                                                         max_df=1.0,\n",
       "                                                                         max_features=None,\n",
       "                                                                         min_df=1,\n",
       "                                                                         ngram_range=(1,\n",
       "                                                                                      2),\n",
       "                                                                         norm='l2',\n",
       "                                                                         preprocessor=None,\n",
       "                                                                         smooth...\n",
       "                                                      max_iter=1000,\n",
       "                                                      n_iter_no_change=5,\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      power_t=0.5,\n",
       "                                                      random_state=None,\n",
       "                                                      shuffle=True, tol=0.001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'lsi__svd__n_components': [10, 100, 150, 200, 250, 300,\n",
       "                                                    400]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'lsi__svd__n_components': [10, 100, 150, 200, 250, 300, 400],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=10, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7444987775061125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred = grid_search.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7561931295848108"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lsi__svd__n_components': 400}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461  1             \n",
       "1  2604  1             \n",
       "2  3341  1             \n",
       "3  3764  1             \n",
       "4  2306  1             "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SUBMISSION 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to your Dataset\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    \n",
    "    'max_depth' : randint(3,10),\n",
    "    'min_samples_leaf': randint(2,15)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue Word Embedding Work Here\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_vectors(docs):\n",
    "    return[nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = ...predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"? \n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "    - What are common applications of sentiment analysis?\n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
